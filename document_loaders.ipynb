{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b4ba9e8",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115765d9",
   "metadata": {},
   "source": [
    "In retrieval augmented generation (RAG), an LLM retrieves contextual documents from an external dataset as part of its execution. \n",
    "\n",
    "This is useful if we want to ask question about specific documents (e.g., our PDFs, a set of videos, etc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d3bd4f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/0f/36/58f4d9df45436670a5b6b82ff48522b6233fa35bd21b133b149c1c7ec8bd/langchain-0.0.352-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.0.352-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\personal\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\personal\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\personal\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Obtaining dependency information for dataclasses-json<0.7,>=0.5.7 from https://files.pythonhosted.org/packages/ae/53/8c006de775834cd4ea64a445402dc195caeebb77dc76b7defb9b3887cb0d/dataclasses_json-0.6.3-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.3-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.2 (from langchain)\n",
      "  Obtaining dependency information for langchain-community<0.1,>=0.0.2 from https://files.pythonhosted.org/packages/bc/69/b97f59cfe0ea85736e0ad0f5c41f37ab713ed1e576e468d72267a1da3d40/langchain_community-0.0.6-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.6-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting langchain-core<0.2,>=0.1 (from langchain)\n",
      "  Obtaining dependency information for langchain-core<0.2,>=0.1 from https://files.pythonhosted.org/packages/42/1e/61e05c0997de81e767a90668f9039771a76dbd474b3d337469501889bc06/langchain_core-0.1.3-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.1.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.70 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.1.0,>=0.0.70 from https://files.pythonhosted.org/packages/c0/a2/7814b2341d2919f8305cdaff2e37f76b04c45839f402a38cf13ef7153bea/langsmith-0.0.75-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.0.75-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\personal\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\personal\\lib\\site-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\personal\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\personal\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\personal\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\personal\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\personal\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\personal\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\personal\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\personal\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\personal\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/ed/3c/cebfdcad015240014ff08b883d1c0c427f2ba45ae8c6572851b6ef136cad/marshmallow-3.20.1-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\personal\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\personal\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain) (3.5.0)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1->langchain)\n",
      "  Obtaining dependency information for packaging<24.0,>=23.2 from https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl.metadata\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\personal\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\personal\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\personal\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\personal\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\personal\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\personal\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\personal\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Downloading langchain-0.0.352-py3-none-any.whl (794 kB)\n",
      "   ---------------------------------------- 0.0/794.4 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/794.4 kB ? eta -:--:--\n",
      "   - ------------------------------------- 30.7/794.4 kB 660.6 kB/s eta 0:00:02\n",
      "   -- ------------------------------------ 41.0/794.4 kB 487.6 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 81.9/794.4 kB 573.4 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 81.9/794.4 kB 573.4 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 92.2/794.4 kB 374.1 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 92.2/794.4 kB 374.1 kB/s eta 0:00:02\n",
      "   ----- -------------------------------- 112.6/794.4 kB 312.2 kB/s eta 0:00:03\n",
      "   ----- -------------------------------- 122.9/794.4 kB 312.9 kB/s eta 0:00:03\n",
      "   ----- -------------------------------- 122.9/794.4 kB 312.9 kB/s eta 0:00:03\n",
      "   ------ ------------------------------- 143.4/794.4 kB 303.9 kB/s eta 0:00:03\n",
      "   ------ ------------------------------- 143.4/794.4 kB 303.9 kB/s eta 0:00:03\n",
      "   ------- ------------------------------ 163.8/794.4 kB 272.8 kB/s eta 0:00:03\n",
      "   ------- ------------------------------ 163.8/794.4 kB 272.8 kB/s eta 0:00:03\n",
      "   ------- ------------------------------ 163.8/794.4 kB 272.8 kB/s eta 0:00:03\n",
      "   ------- ------------------------------ 163.8/794.4 kB 272.8 kB/s eta 0:00:03\n",
      "   -------- ----------------------------- 174.1/794.4 kB 227.9 kB/s eta 0:00:03\n",
      "   -------- ----------------------------- 174.1/794.4 kB 227.9 kB/s eta 0:00:03\n",
      "   -------- ----------------------------- 174.1/794.4 kB 227.9 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 194.6/794.4 kB 218.4 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 194.6/794.4 kB 218.4 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 204.8/794.4 kB 204.2 kB/s eta 0:00:03\n",
      "   ---------- --------------------------- 225.3/794.4 kB 211.7 kB/s eta 0:00:03\n",
      "   ---------- --------------------------- 225.3/794.4 kB 211.7 kB/s eta 0:00:03\n",
      "   ----------- -------------------------- 245.8/794.4 kB 215.3 kB/s eta 0:00:03\n",
      "   ------------ ------------------------- 256.0/794.4 kB 209.7 kB/s eta 0:00:03\n",
      "   ------------ ------------------------- 256.0/794.4 kB 209.7 kB/s eta 0:00:03\n",
      "   ------------- ------------------------ 276.5/794.4 kB 218.4 kB/s eta 0:00:03\n",
      "   ------------- ------------------------ 286.7/794.4 kB 215.8 kB/s eta 0:00:03\n",
      "   -------------- ----------------------- 307.2/794.4 kB 221.0 kB/s eta 0:00:03\n",
      "   --------------- ---------------------- 327.7/794.4 kB 230.9 kB/s eta 0:00:03\n",
      "   ---------------- --------------------- 337.9/794.4 kB 227.9 kB/s eta 0:00:03\n",
      "   ----------------- -------------------- 358.4/794.4 kB 237.0 kB/s eta 0:00:02\n",
      "   ----------------- -------------------- 368.6/794.4 kB 236.4 kB/s eta 0:00:02\n",
      "   ------------------ ------------------- 389.1/794.4 kB 244.9 kB/s eta 0:00:02\n",
      "   -------------------- ----------------- 419.8/794.4 kB 252.1 kB/s eta 0:00:02\n",
      "   --------------------- ---------------- 440.3/794.4 kB 257.2 kB/s eta 0:00:02\n",
      "   --------------------- ---------------- 450.6/794.4 kB 260.9 kB/s eta 0:00:02\n",
      "   ----------------------- -------------- 491.5/794.4 kB 272.5 kB/s eta 0:00:02\n",
      "   ------------------------ ------------- 522.2/794.4 kB 280.1 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 532.5/794.4 kB 283.2 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 553.0/794.4 kB 289.4 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 583.7/794.4 kB 295.9 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 614.4/794.4 kB 302.1 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 645.1/794.4 kB 310.2 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 675.8/794.4 kB 317.9 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 706.6/794.4 kB 325.2 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 747.5/794.4 kB 337.0 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 757.8/794.4 kB 336.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- 794.4/794.4 kB 343.8 kB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.6-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.5 MB 660.6 kB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.1/1.5 MB 653.6 kB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.1/1.5 MB 819.2 kB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.1/1.5 MB 774.0 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.5 MB 807.1 kB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.5 MB 811.5 kB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.3/1.5 MB 787.7 kB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.3/1.5 MB 827.2 kB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.4/1.5 MB 857.5 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.4/1.5 MB 836.4 kB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.4/1.5 MB 860.2 kB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.5/1.5 MB 879.9 kB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.5/1.5 MB 896.4 kB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.6/1.5 MB 901.1 kB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.6/1.5 MB 888.5 kB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.7/1.5 MB 920.8 kB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 930.9 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.8/1.5 MB 934.2 kB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.8/1.5 MB 947.9 kB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.9/1.5 MB 955.1 kB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.9/1.5 MB 961.7 kB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.5 MB 978.6 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.1/1.5 MB 983.5 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.1/1.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.2/1.5 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.2/1.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.4/1.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.4/1.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 1.1 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.1.3-py3-none-any.whl (192 kB)\n",
      "   ---------------------------------------- 0.0/192.4 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 41.0/192.4 kB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 112.6/192.4 kB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 184.3/192.4 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 192.4/192.4 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading langsmith-0.0.75-py3-none-any.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.7/46.7 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.4/49.4 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 0.0/53.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 53.0/53.0 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, packaging, jsonpatch, marshmallow, langsmith, langchain-core, dataclasses-json, langchain-community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 langchain-0.0.352 langchain-community-0.0.6 langchain-core-0.1.3 langsmith-0.0.75 marshmallow-3.20.1 packaging-23.2 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2feda785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/e7/44/5ece9adb8b5943273c845a1e3200168b396f556051b7d2745995abf41584/openai-1.6.1-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\personal\\lib\\site-packages (from openai) (3.5.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/39/9b/4937d841aee9c2c8102d9a4eeb800c7dad25386caabb4a1bf5010df81a57/httpx-0.26.0-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\personal\\lib\\site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: sniffio in c:\\personal\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\personal\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\personal\\lib\\site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\personal\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\personal\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: colorama in c:\\personal\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
      "   ---------------------------------------- 0.0/225.4 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 30.7/225.4 kB 660.6 kB/s eta 0:00:01\n",
      "   ---------- ---------------------------- 61.4/225.4 kB 656.4 kB/s eta 0:00:01\n",
      "   --------------- ----------------------- 92.2/225.4 kB 751.6 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 122.9/225.4 kB 722.1 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 163.8/225.4 kB 821.4 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 204.8/225.4 kB 778.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- 225.4/225.4 kB 765.7 kB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.9 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 30.7/75.9 kB 660.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 75.9/75.9 kB 841.3 kB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.9 kB ? eta -:--:--\n",
      "   --------------------- ------------------ 41.0/76.9 kB 960.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 76.9/76.9 kB 844.3 kB/s eta 0:00:00\n",
      "Installing collected packages: h11, distro, httpcore, httpx, openai\n",
      "Successfully installed distro-1.9.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c697fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "# Set the API key for OpenAI\n",
    "openai.api_key = api_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531bfc31",
   "metadata": {},
   "source": [
    "### PDFS\n",
    "\n",
    "Now, we will load a PDF transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "890aa1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The course will show the pip installs you would need to install packages on your own machine.\n",
    "# These packages are already installed on this platform and should not be run again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe067de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Obtaining dependency information for pypdf from https://files.pythonhosted.org/packages/29/10/055b649e914ad8c5d07113c22805014988825abbeff007b0e89255b481fa/pypdf-3.17.4-py3-none-any.whl.metadata\n",
      "  Downloading pypdf-3.17.4-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading pypdf-3.17.4-py3-none-any.whl (278 kB)\n",
      "   ---------------------------------------- 0.0/278.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/278.2 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/278.2 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 41.0/278.2 kB 388.9 kB/s eta 0:00:01\n",
      "   ------------ -------------------------- 92.2/278.2 kB 655.4 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 225.3/278.2 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 278.2/278.2 kB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-3.17.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1f1e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc473061",
   "metadata": {},
   "source": [
    "Each page is a `Document`.\n",
    "\n",
    "A `Document` contains text (`page_content`) and `metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91836bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43d23486",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9e55eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is ju st spend a little time going over the logistics \n",
      "of the class, and then we'll start to  talk a bit about machine learning.  \n",
      "By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. And so \n",
      "I personally work in machine learning, and I' ve worked on it for about 15 years now, and \n",
      "I actually think that machine learning i\n"
     ]
    }
   ],
   "source": [
    "print(page.page_content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57491143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'MachineLearning-Lecture01.pdf', 'page': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23b0bd6",
   "metadata": {},
   "source": [
    "### YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ae9872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9f9f80",
   "metadata": {},
   "source": [
    "**Note**: This can take several minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0df285b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yt_dlp\n",
      "  Obtaining dependency information for yt_dlp from https://files.pythonhosted.org/packages/31/5a/d9b0a47a3aacf650b8ffc750bb5d296c24b2cc674f4c2a975895f49d4f0a/yt_dlp-2023.11.16-py2.py3-none-any.whl.metadata\n",
      "  Downloading yt_dlp-2023.11.16-py2.py3-none-any.whl.metadata (160 kB)\n",
      "     ---------------------------------------- 0.0/160.5 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/160.5 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/160.5 kB ? eta -:--:--\n",
      "     ------- ----------------------------- 30.7/160.5 kB 217.9 kB/s eta 0:00:01\n",
      "     -------------- ---------------------- 61.4/160.5 kB 297.7 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 153.6/160.5 kB 654.6 kB/s eta 0:00:01\n",
      "     ------------------------------------ 160.5/160.5 kB 642.2 kB/s eta 0:00:00\n",
      "Collecting mutagen (from yt_dlp)\n",
      "  Obtaining dependency information for mutagen from https://files.pythonhosted.org/packages/b0/7a/620f945b96be1f6ee357d211d5bf74ab1b7fe72a9f1525aafbfe3aee6875/mutagen-1.47.0-py3-none-any.whl.metadata\n",
      "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pycryptodomex (from yt_dlp)\n",
      "  Obtaining dependency information for pycryptodomex from https://files.pythonhosted.org/packages/3c/a4/81675804055339db8e277f48bf0012b554a2322f15d000caebf7c8d3f011/pycryptodomex-3.19.0-cp35-abi3-win_amd64.whl.metadata\n",
      "  Downloading pycryptodomex-3.19.0-cp35-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting websockets (from yt_dlp)\n",
      "  Obtaining dependency information for websockets from https://files.pythonhosted.org/packages/d1/40/6b169cd1957476374f51f4486a3e85003149e62a14e6b78a958c2222337a/websockets-12.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading websockets-12.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: certifi in c:\\personal\\lib\\site-packages (from yt_dlp) (2023.7.22)\n",
      "Requirement already satisfied: requests<3,>=2.31.0 in c:\\personal\\lib\\site-packages (from yt_dlp) (2.31.0)\n",
      "Collecting urllib3<3,>=1.26.17 (from yt_dlp)\n",
      "  Obtaining dependency information for urllib3<3,>=1.26.17 from https://files.pythonhosted.org/packages/96/94/c31f58c7a7f470d5665935262ebd7455c7e4c7782eb525658d3dbf4b9403/urllib3-2.1.0-py3-none-any.whl.metadata\n",
      "  Downloading urllib3-2.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting brotli (from yt_dlp)\n",
      "  Obtaining dependency information for brotli from https://files.pythonhosted.org/packages/02/8a/fece0ee1057643cb2a5bbf59682de13f1725f8482b2c057d4e799d7ade75/Brotli-1.1.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading Brotli-1.1.0-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\personal\\lib\\site-packages (from requests<3,>=2.31.0->yt_dlp) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\personal\\lib\\site-packages (from requests<3,>=2.31.0->yt_dlp) (3.4)\n",
      "Downloading yt_dlp-2023.11.16-py2.py3-none-any.whl (3.1 MB)\n",
      "   ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.2/3.1 MB 3.5 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.4/3.1 MB 3.8 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.6/3.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.8/3.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.0/3.1 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.2/3.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.4/3.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.6/3.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.8/3.1 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.0/3.1 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.3/3.1 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.5/3.1 MB 4.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.8/3.1 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.0/3.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.1/3.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.1/3.1 MB 4.3 MB/s eta 0:00:00\n",
      "Downloading urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "   ---------------------------------------- 0.0/104.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 104.6/104.6 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading Brotli-1.1.0-cp311-cp311-win_amd64.whl (357 kB)\n",
      "   ---------------------------------------- 0.0/357.3 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 235.5/357.3 kB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 357.3/357.3 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
      "   ---------------------------------------- 0.0/194.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 194.4/194.4 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading pycryptodomex-3.19.0-cp35-abi3-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.7 MB 2.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.4/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.6/1.7 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.8/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.0/1.7 MB 4.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.0/1.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.0/1.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.1/1.7 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.3/1.7 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.4/1.7 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.5/1.7 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.7 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 2.8 MB/s eta 0:00:00\n",
      "Downloading websockets-12.0-cp311-cp311-win_amd64.whl (124 kB)\n",
      "   ---------------------------------------- 0.0/125.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 125.0/125.0 kB 3.6 MB/s eta 0:00:00\n",
      "Installing collected packages: brotli, websockets, urllib3, pycryptodomex, mutagen, yt_dlp\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.16\n",
      "    Uninstalling urllib3-1.26.16:\n",
      "      Successfully uninstalled urllib3-1.26.16\n",
      "Successfully installed brotli-1.1.0 mutagen-1.47.0 pycryptodomex-3.19.0 urllib3-2.1.0 websockets-12.0 yt_dlp-2023.11.16\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "botocore 1.29.76 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.1.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "#yt-dlp is a command-line program that lets you easily download videos and audio from more than a thousand websites\n",
    "pip install yt_dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c708375f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in c:\\personal\\lib\\site-packages (0.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "969fbc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenAI's whisper model, a speech to text model\n",
    "#to convert YT audio into a text format that we can work with\n",
    "\n",
    "url=\"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\n",
    "save_dir=\"docs/youtube/\"\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url],save_dir),\n",
    "    OpenAIWhisperParser()\n",
    ")\n",
    "\n",
    "#GenericLoader is a combination of\n",
    "#YoutubeAudioLoader and OpenAIWhisperParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43fdb9f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytube\n",
      "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ------------- ------------------------ 20.5/57.6 kB 330.3 kB/s eta 0:00:01\n",
      "     --------------------------------- ---- 51.2/57.6 kB 525.1 kB/s eta 0:00:01\n",
      "     -------------------------------------- 57.6/57.6 kB 503.8 kB/s eta 0:00:00\n",
      "Installing collected packages: pytube\n",
      "Successfully installed pytube-15.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0be9c963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=jGwO_UgTS7I\n",
      "[youtube] jGwO_UgTS7I: Downloading webpage\n",
      "[youtube] jGwO_UgTS7I: Downloading ios player API JSON\n",
      "[youtube] jGwO_UgTS7I: Downloading android player API JSON\n",
      "[youtube] jGwO_UgTS7I: Downloading m3u8 information\n",
      "[info] jGwO_UgTS7I: Downloading 1 format(s): 22\n",
      "[download] Destination: Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018) [jGwO_UgTS7I].mp4\n",
      "[download] 100% of  217.28MiB in 00:00:44 at 4.91MiB/s     \n"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "\n",
    "# URL of the YouTube video\n",
    "url = \"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\n",
    "\n",
    "# Directory to save the downloaded audio file\n",
    "save_dir = \"docs/youtube/\"\n",
    "\n",
    "# FFmpeg location (replace this with your FFmpeg path)\n",
    "ffmpeg_path = r'C:\\Users\\KIIT\\Downloads\\ffmpeg-6.1.tar.xz'\n",
    "\n",
    "# YouTubeDL options including ffmpeg_location\n",
    "ydl_opts = {\n",
    "    'ffmpeg_location': ffmpeg_path,\n",
    "    # You can add more options here if needed\n",
    "}\n",
    "\n",
    "# Download the YouTube video\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download([url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e972734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=jGwO_UgTS7I\n",
      "[youtube] jGwO_UgTS7I: Downloading webpage\n",
      "[youtube] jGwO_UgTS7I: Downloading ios player API JSON\n",
      "[youtube] jGwO_UgTS7I: Downloading android player API JSON\n",
      "[youtube] jGwO_UgTS7I: Downloading m3u8 information\n",
      "[info] jGwO_UgTS7I: Downloading 1 format(s): 140\n",
      "[download] docs\\youtube\\Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a has already been downloaded\n",
      "[download] 100% of   69.76MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\n"
     ]
    },
    {
     "ename": "DownloadError",
     "evalue": "ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPostProcessingError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3465\u001b[0m, in \u001b[0;36mYoutubeDL.process_info\u001b[1;34m(self, info_dict)\u001b[0m\n\u001b[0;32m   3464\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3465\u001b[0m     replace_info_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_process(dl_filename, info_dict, files_to_move))\n\u001b[0;32m   3466\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PostProcessingError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3645\u001b[0m, in \u001b[0;36mYoutubeDL.post_process\u001b[1;34m(self, filename, info, files_to_move)\u001b[0m\n\u001b[0;32m   3644\u001b[0m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__files_to_move\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m files_to_move \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m-> 3645\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_all_pps(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost_process\u001b[39m\u001b[38;5;124m'\u001b[39m, info, additional_pps\u001b[38;5;241m=\u001b[39minfo\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__postprocessors\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   3646\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_pp(MoveFilesAfterDownloadPP(\u001b[38;5;28mself\u001b[39m), info)\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3627\u001b[0m, in \u001b[0;36mYoutubeDL.run_all_pps\u001b[1;34m(self, key, info, additional_pps)\u001b[0m\n\u001b[0;32m   3626\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pp \u001b[38;5;129;01min\u001b[39;00m (additional_pps \u001b[38;5;129;01mor\u001b[39;00m []) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pps[key]:\n\u001b[1;32m-> 3627\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_pp(pp, info)\n\u001b[0;32m   3628\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m info\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3605\u001b[0m, in \u001b[0;36mYoutubeDL.run_pp\u001b[1;34m(self, pp, infodict)\u001b[0m\n\u001b[0;32m   3604\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3605\u001b[0m     files_to_delete, infodict \u001b[38;5;241m=\u001b[39m pp\u001b[38;5;241m.\u001b[39mrun(infodict)\n\u001b[0;32m   3606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PostProcessingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   3607\u001b[0m     \u001b[38;5;66;03m# Must be True and not 'only_download'\u001b[39;00m\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\yt_dlp\\postprocessor\\common.py:23\u001b[0m, in \u001b[0;36mPostProcessorMetaClass.run_wrapper.<locals>.run\u001b[1;34m(self, info, *args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_progress({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarted\u001b[39m\u001b[38;5;124m'\u001b[39m}, info_copy)\n\u001b[1;32m---> 23\u001b[0m ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, info, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\yt_dlp\\postprocessor\\common.py:128\u001b[0m, in \u001b[0;36mPostProcessor._restrict_to.<locals>.decorator.<locals>.wrapper\u001b[1;34m(self, info)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allowed[format_type]:\n\u001b[1;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, info)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\yt_dlp\\postprocessor\\ffmpeg.py:493\u001b[0m, in \u001b[0;36mFFmpegExtractAudioPP.run\u001b[1;34m(self, information)\u001b[0m\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [], information\n\u001b[1;32m--> 493\u001b[0m filecodec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_audio_codec(path)\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filecodec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\yt_dlp\\postprocessor\\ffmpeg.py:241\u001b[0m, in \u001b[0;36mFFmpegPostProcessor.get_audio_codec\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe_available \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavailable:\n\u001b[1;32m--> 241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PostProcessingError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mPostProcessingError\u001b[0m: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDownloadError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m docs \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\langchain_community\\document_loaders\\generic.py:120\u001b[0m, in \u001b[0;36mGenericLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load all documents.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy_load())\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\langchain_community\\document_loaders\\generic.py:115\u001b[0m, in \u001b[0;36mGenericLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_load\u001b[39m(\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    113\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Document]:\n\u001b[0;32m    114\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load documents lazily. Use this when working at a large scale.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m blob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblob_loader\u001b[38;5;241m.\u001b[39myield_blobs():\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblob_parser\u001b[38;5;241m.\u001b[39mlazy_parse(blob)\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\langchain_community\\document_loaders\\blob_loaders\\youtube_audio.py:45\u001b[0m, in \u001b[0;36mYoutubeAudioLoader.yield_blobs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murls:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Download file\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m yt_dlp\u001b[38;5;241m.\u001b[39mYoutubeDL(ydl_opts) \u001b[38;5;28;01mas\u001b[39;00m ydl:\n\u001b[1;32m---> 45\u001b[0m         ydl\u001b[38;5;241m.\u001b[39mdownload(url)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Yield the written blobs\u001b[39;00m\n\u001b[0;32m     48\u001b[0m loader \u001b[38;5;241m=\u001b[39m FileSystemBlobLoader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir, glob\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.m4a\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3511\u001b[0m, in \u001b[0;36mYoutubeDL.download\u001b[1;34m(self, url_list)\u001b[0m\n\u001b[0;32m   3508\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SameFileError(outtmpl)\n\u001b[0;32m   3510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m url_list:\n\u001b[1;32m-> 3511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__download_wrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_info)(\n\u001b[0;32m   3512\u001b[0m         url, force_generic_extractor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforce_generic_extractor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m   3514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_retcode\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3486\u001b[0m, in \u001b[0;36mYoutubeDL.__download_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3483\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   3484\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   3485\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3486\u001b[0m         res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3487\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m UnavailableVideoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   3488\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport_error(e)\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1556\u001b[0m, in \u001b[0;36mYoutubeDL.extract_info\u001b[1;34m(self, url, download, ie_key, extra_info, process, force_generic_extractor)\u001b[0m\n\u001b[0;32m   1554\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m ExistingVideoReached()\n\u001b[0;32m   1555\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__extract_info(url, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_info_extractor(key), download, extra_info, process)\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1558\u001b[0m     extractors_restricted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallowed_extractors\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1567\u001b[0m, in \u001b[0;36mYoutubeDL._handle_extraction_exceptions.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1566\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1567\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1568\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (DownloadCancelled, LazyList\u001b[38;5;241m.\u001b[39mIndexError, PagedList\u001b[38;5;241m.\u001b[39mIndexError):\n\u001b[0;32m   1569\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1723\u001b[0m, in \u001b[0;36mYoutubeDL.__extract_info\u001b[1;34m(self, url, ie, download, extra_info, process)\u001b[0m\n\u001b[0;32m   1721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process:\n\u001b[0;32m   1722\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_video(ie_result)\n\u001b[1;32m-> 1723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_ie_result(ie_result, download, extra_info)\n\u001b[0;32m   1724\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ie_result\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1782\u001b[0m, in \u001b[0;36mYoutubeDL.process_ie_result\u001b[1;34m(self, ie_result, download, extra_info)\u001b[0m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_extra_info(ie_result, extra_info)\n\u001b[1;32m-> 1782\u001b[0m     ie_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_video_result(ie_result, download\u001b[38;5;241m=\u001b[39mdownload)\n\u001b[0;32m   1783\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_pending_errors(ie_result)\n\u001b[0;32m   1784\u001b[0m     additional_urls \u001b[38;5;241m=\u001b[39m (ie_result \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madditional_urls\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:2922\u001b[0m, in \u001b[0;36mYoutubeDL.process_video_result\u001b[1;34m(self, info_dict, download)\u001b[0m\n\u001b[0;32m   2920\u001b[0m downloaded_formats\u001b[38;5;241m.\u001b[39mappend(new_info)\n\u001b[0;32m   2921\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2922\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_info(new_info)\n\u001b[0;32m   2923\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MaxDownloadsReached:\n\u001b[0;32m   2924\u001b[0m     max_downloads_reached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3467\u001b[0m, in \u001b[0;36mYoutubeDL.process_info\u001b[1;34m(self, info_dict)\u001b[0m\n\u001b[0;32m   3465\u001b[0m     replace_info_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_process(dl_filename, info_dict, files_to_move))\n\u001b[0;32m   3466\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PostProcessingError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3467\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport_error(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPostprocessing: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(err))\n\u001b[0;32m   3468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   3469\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1045\u001b[0m, in \u001b[0;36mYoutubeDL.report_error\u001b[1;34m(self, message, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreport_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, message, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;124;03m    Do the same as trouble, but prefixes the message with 'ERROR:', colored\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;124;03m    in red if stderr is a tty file.\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m-> 1045\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrouble(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_err(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mStyles\u001b[38;5;241m.\u001b[39mERROR)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\personal\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:984\u001b[0m, in \u001b[0;36mYoutubeDL.trouble\u001b[1;34m(self, message, tb, is_error)\u001b[0m\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    983\u001b[0m         exc_info \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n\u001b[1;32m--> 984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DownloadError(message, exc_info)\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_retcode \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mDownloadError\u001b[0m: ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location"
     ]
    }
   ],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ff566c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFile not found · GitHub\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle navigation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Sign in\\n        \\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Product\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nActions\\n        Automate any workflow\\n      \\n\\n\\n\\n\\n\\n\\n\\nPackages\\n        Host and manage packages\\n      \\n\\n\\n\\n\\n\\n\\n\\nSecurity\\n        Find and fix vulnerabilities\\n      \\n\\n\\n\\n\\n\\n\\n\\nCodespaces\\n        Instant dev environments\\n '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d322ed67",
   "metadata": {},
   "source": [
    "### URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e629c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://github.com/basecamp/handbook/blob/master/37signals-is-you.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0cf75f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a96a28d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "File not found · GitHub\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle navigation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Sign in\n",
      "        \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        Product\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Actions\n",
      "        Automate any workflow\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Packages\n",
      "        Host and manage packages\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Security\n",
      "        Find and fix vulnerabilities\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Codespaces\n",
      "        Instant dev environments\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7dbcda",
   "metadata": {},
   "source": [
    "### Notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab19579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "loader = NotionDirectoryLoader(\"docs/Notion_DB.md\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44675413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No documents loaded from the Notion directory.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "\n",
    "# Assuming your Notion directory contains documents\n",
    "notion_dir_path = \"docs/Notion_DB.md\"\n",
    "\n",
    "# Create a loader for the Notion directory\n",
    "loader = NotionDirectoryLoader(notion_dir_path)\n",
    "\n",
    "# Load the documents\n",
    "docs = loader.load()\n",
    "\n",
    "# Check if there are any documents loaded\n",
    "if docs:\n",
    "    # Access content from the first document in the list\n",
    "    first_doc_content = docs[0].page_content if docs[0].page_content else \"No content found\"\n",
    "    print(first_doc_content[0:200])  # Print the first 200 characters of the content\n",
    "else:\n",
    "    print(\"No documents loaded from the Notion directory.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
